\chapter{Simulations}
\label{ch:simulations}

Simulations which are used to better understand measured data and the
detectors are explained in detail in this chapter. First the simulation
of the air showers which are the input for the detector simulation is
explained. Both Monte Carlo simulations of air showers and
parametric/formulas/.. describing the time and density structures of the
shower fronts are used.


\section{Monte Carlo extensive air shower simulation}

For the simulation of cosmic-ray induced air showers there are several
programs available, most notably \corsika and \aires\cite{sciutto1999}.
\corsika was chosen because it is still being actively worked on, unlike
\aires which received its last update in 2006. \corsika also includes
updated models based on recent LHC data. Additionally, \corsika is widely
used by other cosmic-ray experiments.

\corsika version 74000 is used. \corsika provides the choice from many
models for various interactions. For high energy hadronic interactions;
DPMJET, EPOS LHC\cite{pierog2013}, NEXUS, QGSJET,
QGSJETII-04\cite{ostapchenko2013}, SIBYLL, and VENUS are available. For
hadrons with energies below \SI{80}{\GeV}
GHEISHA\cite{fesefeldt1985}, FLUKA, or URQMD can be selected.
Electromagnetic interactions can be treated by EGS4\cite{egs4} code or
by NKG formulas.

From these options QGSJETII, GHEISHA and EGS4 were chosen. QGSJETII was chosen
because it has been tuned with LHC data, and performs similar to EPOS, though
both are not perfect (see ICRC2015 talks). Moreover, QGSJETII is easier to
setup and faster than EPOS. One configuration of \corsika was compiled and all
showers were run using that executable.

% From CORSIKA manual:
%
% - The QGSJETII04 option needs about 3 times more CPU-time than the HDPM
%   option (NKG enabled, EGS4 disabled).
% - The EPOS option needs roughly 7.5 times more CPU-time than the VENUS
%   option (E0 = 1015 eV, NKG enabled, EGS4 disabled).
% - The VENUS option needs roughly 15 times more CPU-time than the HDPM
%   option (NKG enabled, EGS4 disabled).
%
% So the EPOS option needs 7.5 x 15 = 112.5 times more CPU-time than the
% QGSJETII option.


\subsection{Shower parameters}

The simulations are steered by an input file, many parameters can be set
here. The default options are used whenever applicable and trusting(?)
in sensibly chosen defaults. The seeds for the random number generators
(first for the hadron shower, second for EGS4) are chosen to be
different for each run. The seed values are, in this case, also used as
unique identifiers for the simulations, so each combination of two seeds
is unique in the dataset of simulations. Only one shower is simulated
per run. Each run is for a specific particle with a specific energy
between \SIrange{e12}{e18}{\eV} in steps of $\log E = .5$
(in eV). The zenith angle is also set for each run and is varied from
\SIrange{0}{60}{\degree} in steps of \SI{7.5}{\degree}. The azimuthal
angle is usually set to \SI{0}{\degree} (\hisparc coordinate system),
but can be varied in steps of \SI{45}{\degree}. The magnetic field
values have been modified to values for Amsterdam [ref].


\subsubsection{Primary particle}

Given the high abundance of protons as primary particles and iron with a
relative high abundance for heavier nuclei we have mostly focused on
those two particles for the simulations. However, small datasets with
other primaries have also been created. For protons all possible
combinations of energy and zenith have been simulated at least 10 times.
Most showers are available at \SI{22.5}{\degree} zenith angle and
\SI{e16}{\eV}. Larger showers take up much more disk space and
time to compute. In \cref{fig:simulations_proton_energy_zenith} the
number of simulations for each combination of parameters for proton
primaries can be seen. (at time of writing..)


\subsubsection{Energy cuts}

Energy cuts \SI{300}{\MeV} for hadrons and muons, and
\SI{3}{\MeV} for electrons and photons. Below these
energies the particles are quickly stopped/slowed by the atmosphere
decay [ref PDG, fig 28.5]. The observation level for all runs is set to
\SI{10}{\meter} above sea level, which is relevant for the Science Park
where ground level is \SI{3.7}{\meter} below sea level, and the detector
stations are on the roofs of buildings.


\subsection{Stoomboot}

To run a significant number of simulations the local Nikhef computer
cluster 'Stoomboot' was utilized. This cluster used to have around 300
CPUs available, but was expanded in February 2014 to over 800 CPUs. Job
queueing uses a fair-use policy to give each group at Nikhef equal
access to computation time.

Simulation time for each simulation is different because the number of
particles in a simulations will be different each run. Stoomboot has a
maximum job time of \SI{96}{\hour}. This allows for showers with primary
energies upto \SI{e17}{\eV}, which take around 60 hours to
complete. A large sample of showers can easily be generated by running
many jobs simultaneously.

Since there are also parimary particles with energies above
\SI{e17}{\eV} some simulations at higher energies are desired.
During the 2014 Christmas holidays 285 jobs at energies
\SIrange{e17.5}{e18}{\eV} were run. This was a special run
where the maximum job time had been manually extended by a Stoomboot
administrator. The longest jobs took over \SI{480}{\hour} (i.e.
\SI{20}{\day}) to complete. In total almost \SI{50}{\year} of CPU time
was used to generate the simulation sample.

\begin{figure} \centering \input{plots/simulations/shower_walltime}
\caption{\captitle{Walltime for \corsika simulations.}}
\label{fig:simulations_shower_walltime} \end{figure}


\subsection{No thinning}

\corsika provides a thinning mechanism to reduce the computation time.
Thinning looks at particles emerging from interactions and takes those
below a set fraction of the primary particle energy and drops all but
one of those. The particle that is kept is given a weight to represent
the dropped particles. Some information is lost when thinning.

The thinning mechanism has not been enabled. Using Stoomboot enough
computational time was available to run \SI{e18}{\eV} showers
without thinning.

For higher energies thinning might be required to keep run times
reasonable. However, thinned data provides different output, not one
particle for each particle on the ground, instead some particles have
weights and can represent more than one particle. This format is
currently incompatible with the detector simulation. A dethinning
algorithm exists \cite{stokes2012} which can unravel the weighted
particles into separate particles, of course some information is lost.

However, as shown by [Sabine] the number of showers with primary
energies above \SI{e18}{\eV} is minimal with the Science park
cluster of \hisparc. Therefore simulated showers with higher energies
are not necessary, moreover, the larger file sizes make it harder to
use them.


\subsection{Simulations catalogue}

Using Stoomboot a collection of over \num{70000} simulated showers has
been created. This data is stored on the \hisparc data server (trave)
which has \SI{37}{\tera\byte} space. This space is shared with the raw
\hisparc data (cosmic and weather), \knmi lightning data, and some
analysis files from various \hisparc collaborators.

For easy use with the \sapphire framework the \corsika simulations are
converted from the sequential unformatted \fortran data format to \hdf
format. This is done using a modified version of the the Python \corsika
Reader package \cite{gonzalez2011}. During the conversion the values are
(when applicable) converted to the units and coordinate systems used in
\hisparc [see appendix].

After the initial conversion further optimisation is performed by
sorting and indexing the 'x' coordinate column for the particles. In the
detector simulation particles are queried from the \corsika data file
using x and y coordinates. With the index it is very easy for the
software to know which part of the data it needs, since the data is
sorted (on disk) only a small part of the data needs to be read into
memory, if the data was not sorted more chunks of the file would need to
be read into memory. In some cases the sorting speeds up simulations by
a factor of 50 \cite{pytables:optimization}.

\todo{Update plot with intermediate energies, and 'color bar', also one
for iron?}

\begin{figure}
    \centering
    \input{plots/simulations/energy_zenith_proton}
    \caption{\captitle{Proton simulations overview.} The square of the
             area of the rectangles indicate the number simulations with
             that energy and zenith combinations with a proton primary.}
    \label{fig:simulations_proton_energy_zenith}
\end{figure}


\subsubsection{Simulation overview}

In order to find a suitable \corsika simulation for detector simulations
an overview (\hdf) of all \corsika simulations is generated. The
overview contains the variable input parameters, the number of particles
on ground level, and the height of first interaction for each
simulation.


\section{Detector simulation}

The detector and station responses and accuracies reported in [chapters
detector/station] are implemented in the detector simulations. These
routines provide the station response to air showers.

As input the \corsika showers can be used, but the simulation also
provides analytical functions that describe the particle densities as
function of the core distance (Ldf) and those that contain the time
structure of the shower front.

The same cluster objects (containing detector positions) that are used
in reconstructions are used as input for simulations.


\subsection{Simulation steps}

The detector simulation requires a cluster of stations as input, upon
which the showers will be thrown. The same type of cluster object is
used in reconstructions. Depending on the type of simulation a \corsika
data file may also be required as input. Finally a sensible maximum core
distance and number of iterations can be chosen. For each iteration the following steps are taken.

Generate shower parameters; core position, azimuth angle, and timestamp
A random position within a given radius around the cluster origin is
generated for the shower core position.

Instead of shifting and rotating the particles in the \corsika file the
cluster and detector positions are shifted. Performing computations on
the \corsika data prevents queries from using the table indexes.

Then for each station each detector is simulated.

For each detector the particles which pass through it are selected, then the detector response is determined (i.e. total signal strength and time of first
particle). Though the orientation of the individual detectors on Science
Park is known, this information is not used in the default simulation.
Instead a square with \SI{.5}{\meter\square} area is used for a simpler query
which simply checks for all leptons (and gamma?) where the x and y are
within .. of he detector center. If the oriëntation of detectors is also
used the boundary lines have to be computed and a more complicated query
is used. This query can still used the data index by first selecting a
larger bounding square in which the whole detector is contained
regardles of oriëntation. This approximation means that at most
\SI{29.2}{\percent} of the detector surface is not in its actual
location, but still connected to the detector. However, other source for
error: Poisson, GPS, detector measurement.

Then it is determined if the station triggered or not. This uses the
same trigger logic as the \hisparc stations. For 4-detector stations
either 2-high or 3-low, and for 2-detector stations 2-low. The
thresholds are set at a fraction of a particle, MPV peak.. Relation
between pulse height and integral in data, spread..

If a station triggered its event is stored, containing an extended
timestamp, arrival times and particle counts.

Finally a coincidence is saved with links to the station events (for
stations that triggered) and the input shower paramters. A coincidence
is also saved if there are no events, which can be used to determine the
trigger efficiency.


\section{Realistic simulation}

In order to perform realistic simulations the cosmic-ray energy spectrum
must be considered.

\todo{Simulation with fluxes and azimuth/zenith distributions.}

\todo{Acceptance; angle, energy and particles.}

See detector response, cluster response and calibration.


\section{Analysis}

From the simulated dataset we can extract the characteristics of air showers. This gives in sight into the timing distribution of the various particle components in the shower front, the shape of the shower front, and the spacial distribution of the particles on the ground. The variation from shower to shower with the same starting parameters can be estimated, these variations limit the accuracy of the shower reconstruction.

\begin{figure}
    \centering
    \input{plots/simulations/shower_sizes}
    \caption{\captitle{Shower size versus zenith angle and primary energy.}
             Each line indicates the median shower size for a specific
             energy as a function of zenith angle. The gray area
             indicates the 16th and 84th percentile.}
    \label{fig:simulations_shower_sizes}
\end{figure}
